{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Synonym dictionary for skills standardization\n",
    "synonym_dict = {\n",
    "    'ML': 'machine learning',\n",
    "    'AI': 'artificial intelligence',\n",
    "    'k8s': 'kubernetes',\n",
    "    'sql': 'database management',\n",
    "}\n",
    "\n",
    "# Function to replace synonyms\n",
    "def replace_synonyms(skills):\n",
    "    return [synonym_dict.get(skill.lower(), skill.lower()) for skill in skills]\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [synonym_dict.get(token.lemma_, token.lemma_) for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Function to parse raw entries\n",
    "def parse_raw_entry(raw_entry):\n",
    "    try:\n",
    "        # Attempt to parse as standard JSON\n",
    "        parsed_entry = json.loads(raw_entry)\n",
    "        return parsed_entry\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # Handle raw, malformed entries\n",
    "        lines = raw_entry.split(\"\\n\")\n",
    "        structured_entry = {\"college name\": None, \"10th marks\": None, \"12th marks\": None, \"CGPA\": None, \"skills\": []}\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"* College Name:\"):\n",
    "                structured_entry[\"college name\"] = line.replace(\"* College Name:\", \"\").strip()\n",
    "            elif line.startswith(\"* 10th Marks:\"):\n",
    "                structured_entry[\"10th marks\"] = line.replace(\"* 10th Marks:\", \"\").strip()\n",
    "            elif line.startswith(\"* 12th Marks:\"):\n",
    "                structured_entry[\"12th marks\"] = line.replace(\"* 12th Marks:\", \"\").strip()\n",
    "            elif line.startswith(\"* CGPA:\"):\n",
    "                structured_entry[\"CGPA\"] = line.replace(\"* CGPA:\", \"\").strip()\n",
    "            elif line.startswith(\"* Skills:\"):\n",
    "                skills_part = line.replace(\"* Skills:\", \"\").strip()\n",
    "                skills = [skill.strip() for skill in skills_part.split(\",\") if skill.strip()]\n",
    "                structured_entry[\"skills\"].extend(skills)\n",
    "\n",
    "        return structured_entry\n",
    "\n",
    "# Function to clean raw extractions\n",
    "def clean_extractions(data):\n",
    "    for entry in data:\n",
    "        if \"error\" in entry:\n",
    "            # Skip entries with errors\n",
    "            continue\n",
    "        response = entry.get(\"response\")\n",
    "        if isinstance(response, str):  # Detect raw string format\n",
    "            entry[\"response\"] = parse_raw_entry(response)\n",
    "    return data\n",
    "\n",
    "# Extract valid resumes\n",
    "def extract_valid_resumes(data):\n",
    "    resumes = []\n",
    "    for entry in data:\n",
    "        response = entry.get(\"response\")\n",
    "        if response:\n",
    "            skills = replace_synonyms(response.get(\"skills\", []))\n",
    "            resumes.append({\n",
    "                \"file_name\": entry[\"file_name\"],\n",
    "                \"skills\": \" \".join(skills),\n",
    "                \"10th_marks\": response.get(\"10th marks\"),\n",
    "                \"12th_marks\": response.get(\"12th marks\"),\n",
    "                \"CGPA\": response.get(\"CGPA\"),\n",
    "            })\n",
    "    return pd.DataFrame(resumes)\n",
    "\n",
    "# Skip normalization for CGPA and marks\n",
    "def normalize_features(df, columns):\n",
    "    \"\"\"\n",
    "    Normalize numerical features (e.g., marks and CGPA) and handle non-numeric data.\n",
    "    Skips normalization for non-numeric columns like CGPA and marks.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        if col in ['10th_marks', '12th_marks', 'CGPA']:\n",
    "            continue  # Skip these columns from normalization\n",
    "        df[col] = df[col].fillna(0)  # Fill missing values with 0 (or use another strategy)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(df, job_description):\n",
    "    job_vector = nlp(preprocess_text(job_description)).vector\n",
    "\n",
    "    if job_vector is None or len(job_vector) == 0:\n",
    "        raise ValueError(\"Job description vector is invalid.\")\n",
    "\n",
    "    # Generate skill vectors for resumes, replacing empty ones with zeros\n",
    "    df['Skill_Vector'] = df['skills'].apply(\n",
    "        lambda x: nlp(x).vector if isinstance(x, str) and x.strip() else np.zeros(nlp.vocab.vectors_length)\n",
    "    )\n",
    "\n",
    "    # Remove rows with invalid skill vectors\n",
    "    df = df[df['Skill_Vector'].apply(lambda x: np.any(x))]\n",
    "\n",
    "    # Compute similarity scores based on skill vectors\n",
    "    similarity_scores = [\n",
    "        cosine_similarity(vec.reshape(1, -1), job_vector.reshape(1, -1))[0][0]\n",
    "        for vec in df['Skill_Vector']\n",
    "    ]\n",
    "\n",
    "    df['Similarity_Score'] = similarity_scores\n",
    "\n",
    "    # Sort by similarity score, take the top 10, and ensure it's a DataFrame\n",
    "    top_10_resumes = df[['file_name', 'Similarity_Score', '10th_marks', '12th_marks', 'CGPA']].sort_values(\n",
    "        by='Similarity_Score', ascending=False\n",
    "    ).head(10)\n",
    "\n",
    "    return pd.DataFrame(top_10_resumes)\n",
    "\n",
    "\n",
    "\n",
    "# Main function\n",
    "def rank_resumes(json_path, job_description):\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    cleaned_data = clean_extractions(data)\n",
    "\n",
    "    # Extract valid resumes and preprocess\n",
    "    resumes_df = extract_valid_resumes(cleaned_data)\n",
    "    resumes_df = normalize_features(resumes_df, ['10th_marks', '12th_marks', 'CGPA'])\n",
    "\n",
    "    ranked_df = compute_similarity(resumes_df, job_description)\n",
    "    return ranked_df.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              file_name  Similarity_Score 10th_marks  \\\n",
      "61          22220131_ARYAN_LAD_VIIT.pdf          0.922561       None   \n",
      "39  22110633_ATHARVA_NANDURKAR_VIIT.pdf          0.915797       None   \n",
      "45    22110712_SANDESH_BUCHKUL_VIIT.pdf          0.900788       None   \n",
      "44   22110709_PRASAD_KANAKGIRI_VIIT.pdf          0.900788       None   \n",
      "43      22110705_PRAJWAL_PATIL_VIIT.pdf          0.900765       None   \n",
      "47       22110724_GANESH_JOSHI_VIIT.pdf          0.894242       None   \n",
      "32     22110511_APURVA_BELSARE_VIIT.pdf          0.885377       None   \n",
      "76      22220287_MUSKAN_SHAIKH_VIIT.pdf          0.885334       None   \n",
      "74     22220262_PUSHKAR_INGALE_VIIT.pdf          0.885190       None   \n",
      "56        22110853_KUSHAL_MALU_VIIT.pdf          0.882646       None   \n",
      "\n",
      "   12th_marks          CGPA  \n",
      "61       None          None  \n",
      "39       None          9.23  \n",
      "45       None       9.03/10  \n",
      "44       None     8.79/10.0  \n",
      "43       None  8.95 / 10.00  \n",
      "47       None          8.95  \n",
      "32       None          8.93  \n",
      "76       None          9.08  \n",
      "74       None          9.45  \n",
      "56       None           9.1  \n",
      "Ranked resumes have been saved to ranked_resumes.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaush\\AppData\\Local\\Temp\\ipykernel_21688\\1425498315.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Similarity_Score'] = similarity_scores\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_path = \"bulk_responses.json\"  # Replace with your JSON file path\n",
    "    job_description_path = \"job1.txt\"  # Path to your job description file\n",
    "\n",
    "    # Read job description from file\n",
    "    with open(job_description_path, 'r', encoding='utf-8') as file:\n",
    "        job_description = file.read().strip()  # Read and clean up whitespace\n",
    "\n",
    "    # Rank resumes based on the job description\n",
    "    ranked_resumes = rank_resumes(json_path, job_description)\n",
    "\n",
    "    # Display the top 10 resumes\n",
    "    print(ranked_resumes)\n",
    "\n",
    "    # Save the ranked resumes to a JSON file\n",
    "    json_output_path = \"ranked_resumes.json\"  # Path for the JSON output file\n",
    "    ranked_resumes.to_json(json_output_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(f\"Ranked resumes have been saved to {json_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
